{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c35a5b01828a4cdc962f1f749b451ded": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec535feda363412b976c7ce939a53b3c",
              "IPY_MODEL_18f510767b8942b784cb1b657ca5020d",
              "IPY_MODEL_5044ba0db28b4c58ac48cc3cd7bc58d1"
            ],
            "layout": "IPY_MODEL_6bb2d4eade0541b1b7e0ff5509f3e278"
          }
        },
        "ec535feda363412b976c7ce939a53b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc1d86f0cb6486c8d426436a1e0643a",
            "placeholder": "​",
            "style": "IPY_MODEL_5d7dae83338641b7971d0f34f7a53eb2",
            "value": "Epoch:   0%"
          }
        },
        "18f510767b8942b784cb1b657ca5020d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1087c2f33c3a4010b3eaf6d476f6ffdd",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbac255c43024943831d8255297d1671",
            "value": 0
          }
        },
        "5044ba0db28b4c58ac48cc3cd7bc58d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0291a05c3a174b3598f91795c82565b9",
            "placeholder": "​",
            "style": "IPY_MODEL_71862daff860477d8e0ad8077e81fea4",
            "value": " 0/10 [00:00&lt;?, ?it/s]"
          }
        },
        "6bb2d4eade0541b1b7e0ff5509f3e278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bc1d86f0cb6486c8d426436a1e0643a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7dae83338641b7971d0f34f7a53eb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1087c2f33c3a4010b3eaf6d476f6ffdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbac255c43024943831d8255297d1671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0291a05c3a174b3598f91795c82565b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71862daff860477d8e0ad8077e81fea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d51054dee4ed4d328aac1861ebee8ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f199663bddec4981a32cf48e83bd240a",
              "IPY_MODEL_d0063e5676f341a2ba03290f3d3cc965",
              "IPY_MODEL_e3b292a91c154628a9c4ffe4818f1858"
            ],
            "layout": "IPY_MODEL_f5b1870605f940adaeaaedcc0dc53b1b"
          }
        },
        "f199663bddec4981a32cf48e83bd240a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5161cf9e50904688997f78c41eeeed3d",
            "placeholder": "​",
            "style": "IPY_MODEL_282afba645e640bf9ae57ef45aecb27b",
            "value": "Training:  88%"
          }
        },
        "d0063e5676f341a2ba03290f3d3cc965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e854655767c845c6b12c1b6cd5c6fd30",
            "max": 534,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_047aad51e53143e191b6b6b2a7798ad9",
            "value": 471
          }
        },
        "e3b292a91c154628a9c4ffe4818f1858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e50c09f0ab94f96a7e79dbaf74a52de",
            "placeholder": "​",
            "style": "IPY_MODEL_501520f60bd7451e83ba32125c8b2932",
            "value": " 471/534 [05:43&lt;00:59,  1.06it/s]"
          }
        },
        "f5b1870605f940adaeaaedcc0dc53b1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5161cf9e50904688997f78c41eeeed3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "282afba645e640bf9ae57ef45aecb27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e854655767c845c6b12c1b6cd5c6fd30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "047aad51e53143e191b6b6b2a7798ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e50c09f0ab94f96a7e79dbaf74a52de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501520f60bd7451e83ba32125c8b2932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melsonwang1/CVNL-assignment/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4eTGC6tmHnLq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d0dbc7-775c-4336-d354-961083f17824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "drive  sample_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/idlmam.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cd /content/drive/My\\ Drive/Colab\\ Notebooks/\n",
        "!ls\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/')\n",
        "from idlmam  import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unicodedata\n",
        "import string\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "3TCLbb_J9Yd9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6buiYJ563q9",
        "outputId": "6e480881-535a-4e0d-8c6e-53d6e5a8761d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "cache_dir = os.path.expanduser(\"~/.cache/huggingface/datasets\")\n",
        "if os.path.exists(cache_dir):\n",
        "    shutil.rmtree(cache_dir)\n",
        "    print(\"Cache cleared.\")\n"
      ],
      "metadata": {
        "id": "PVQZXi_ucFcn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"go_emotions\", download_mode=\"force_redownload\")\n",
        "\n",
        "# Check the dataset structure\n",
        "print(dataset)\n",
        "label_mapping = dataset[\"train\"].features[\"labels\"].feature.names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "lSaeUc5qGE9W",
        "outputId": "1a9ce123-c013-4e35-8786-899db66a99d9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ConnectionError",
          "evalue": "Couldn't reach 'go_emotions' on the Hub (LocalEntryNotFoundError)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-861b9dc0980d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"go_emotions\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"force_redownload\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Check the dataset structure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, keep_in_memory, save_infos, revision, token, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[0;31m# Create a dataset builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2129\u001b[0;31m     builder_instance = load_dataset_builder(\n\u001b[0m\u001b[1;32m   2130\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0mdownload_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdownload_config\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mDownloadConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1848\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1849\u001b[0;31m     dataset_module = dataset_module_factory(\n\u001b[0m\u001b[1;32m   1850\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1729\u001b[0m                             \u001b[0;34mf\"Couldn't find '{path}' on the Hugging Face Hub either: {type(e1).__name__}: {e1}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1730\u001b[0m                         ) from None\n\u001b[0;32m-> 1731\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1732\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1733\u001b[0m         raise FileNotFoundError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/datasets/load.py\u001b[0m in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1616\u001b[0m                     ),\n\u001b[1;32m   1617\u001b[0m                 ):\n\u001b[0;32m-> 1618\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Couldn't reach '{path}' on the Hub ({e.__class__.__name__})\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1619\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mConnectionError\u001b[0m: Couldn't reach 'go_emotions' on the Hub (LocalEntryNotFoundError)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OnDK5mXN9KUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_data = {}\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "alphabet = {}\n",
        "for i in range(n_letters):\n",
        "  alphabet[all_letters[i]] = i\n",
        "\n",
        "\n",
        "def unicodeToAscii(s):\n",
        "    # Turns a Unicode string into plain ASCII\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn' and c in all_letters\n",
        "    )\n",
        "\n",
        "for sample in dataset[\"train\"]:\n",
        "    text = sample[\"text\"]  # The text sample\n",
        "    labels = sample[\"labels\"]  # The list of labels for this sample\n",
        "\n",
        "    # Normalize the text using the unicodeToAscii function\n",
        "    normalized_text = unicodeToAscii(text).lower()\n",
        "\n",
        "    # Loop through all labels for this sample (in case there are multiple labels)\n",
        "    for label in labels:\n",
        "        emotion = label_mapping[label]  # Map label index to emotion name\n",
        "\n",
        "        # Add to the emotion_data dictionary\n",
        "        if emotion not in emotion_data:\n",
        "            emotion_data[emotion] = []  # Initialize the list for this emotion\n",
        "        emotion_data[emotion].append(normalized_text)\n",
        "\n",
        "# Print out the emotion names and their respective text count\n",
        "for emotion, texts in emotion_data.items():\n",
        "    print(f\"{emotion}: {len(texts)} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "CiITXAm2Gste",
        "outputId": "73b0a919-99ff-42a8-82b9-f502953220d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f4c0077f2da5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# The text sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# The list of labels for this sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LanguageNameDataset(Dataset):\n",
        "\n",
        "    def __init__(self, lang_name_dict, vocabulary):\n",
        "      self.label_names = [x for x in lang_name_dict.keys()]\n",
        "      self.data = []\n",
        "      self.labels = []\n",
        "      self.vocabulary = vocabulary\n",
        "      for y, language in enumerate(self.label_names):\n",
        "          for sample in lang_name_dict[language]:\n",
        "              if len(sample) > 0:  # Filter out empty inputs\n",
        "                  self.data.append(sample)\n",
        "                  self.labels.append(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def string2InputVec(self, input_string):\n",
        "        \"\"\"\n",
        "        This method will convert any input string into a vector of long\n",
        "        values, according to the vocabulary used by this object.\n",
        "        input_string: the string to convert to a tensor\n",
        "        \"\"\"\n",
        "\n",
        "        T = len(input_string) #How many characters long is the string?\n",
        "\n",
        "        #Create a new tensor to store the result\n",
        "        name_vec = torch.zeros((T), dtype=torch.long)\n",
        "        #iterate through the string and place the appropriate values into the tensor\n",
        "        for pos, character in enumerate(input_string):\n",
        "            name_vec[pos] = self.vocabulary[character]\n",
        "\n",
        "        return name_vec\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        #Convert the correct class label into a tensor for PyTorch\n",
        "        label_vec = torch.tensor([label], dtype=torch.long)\n",
        "\n",
        "        return self.string2InputVec(name), label\n"
      ],
      "metadata": {
        "id": "f_rHXDZQI5K9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = LanguageNameDataset(emotion_data, alphabet)\n",
        "\n",
        "# Limit the dataset size to 20,000 samples\n",
        "total_size = min(len(dataset), 30000)  # Use the smaller of the dataset size or 20,000\n",
        "\n",
        "# Define proportions\n",
        "train_ratio = 0.8  # 80% training\n",
        "test_ratio = 0.2   # 20% testing\n",
        "\n",
        "# Compute split sizes\n",
        "train_size = int(train_ratio * total_size)\n",
        "test_size = total_size - train_size\n",
        "\n",
        "# Take a subset of the dataset if the dataset is larger than 20,000\n",
        "subset_indices = torch.randperm(len(dataset))[:total_size]  # Randomly select 20,000 indices\n",
        "subset_dataset = torch.utils.data.Subset(dataset, subset_indices)\n",
        "\n",
        "# Randomly split the subset dataset\n",
        "train_data, test_data = torch.utils.data.random_split(subset_dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "e-EX3nhw8r_d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def pad_and_pack(batch):\n",
        "    #1, 2, & 3: organize the batch input lengths, inputs, and outputs as seperate lists\n",
        "    input_tensors = []\n",
        "    labels = []\n",
        "    lengths = []\n",
        "    for x, y in batch:\n",
        "        input_tensors.append(x)\n",
        "        labels.append(y)\n",
        "        lengths.append(x.shape[0]) #Assume shape is (T, *)\n",
        "\n",
        "    #4: create the padded version of the input\n",
        "    x_padded = torch.nn.utils.rnn.pad_sequence(input_tensors, batch_first=False)\n",
        "    #5: create the packed version from the padded & lengths\n",
        "    x_packed = torch.nn.utils.rnn.pack_padded_sequence(x_padded, lengths, batch_first=False, enforce_sorted=False)\n",
        "    #Convert the lengths into a tensor\n",
        "    y_batched = torch.as_tensor(labels, dtype=torch.long)\n",
        "\n",
        "    #6: return a tuple of the packed inputs and their labels\n",
        "    return x_packed, y_batched\n"
      ],
      "metadata": {
        "id": "vXR3zy_tJ5yP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EmbeddingPackable(nn.Module):\n",
        "    \"\"\"\n",
        "    The embedding layer in PyTorch does not support Packed Sequence objects.\n",
        "    This wrapper class will fix that. If a normal input comes in, it will\n",
        "    use the regular Embedding layer. Otherwise, it will work on the packed\n",
        "    sequence to return a new Packed sequence of the appropriate result.\n",
        "    \"\"\"\n",
        "    def __init__(self, embd_layer):\n",
        "        super(EmbeddingPackable, self).__init__()\n",
        "        self.embd_layer = embd_layer\n",
        "\n",
        "    def forward(self, input):\n",
        "        if type(input) == torch.nn.utils.rnn.PackedSequence:\n",
        "            # We need to unpack the input,\n",
        "            sequences, lengths = torch.nn.utils.rnn.pad_packed_sequence(input.cpu(), batch_first=True)\n",
        "            #Embed it\n",
        "            sequences = self.embd_layer(sequences.to(input.data.device))\n",
        "            #And pack it into a new sequence\n",
        "            return torch.nn.utils.rnn.pack_padded_sequence(sequences, lengths.cpu(),\n",
        "                                                           batch_first=True, enforce_sorted=False)\n",
        "        else:#apply to normal data\n",
        "            return self.embd_layer(input)\n"
      ],
      "metadata": {
        "id": "tyDRlFgqJ-Jl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = LanguageNameDataset(emotion_data, alphabet)\n",
        "\n",
        "# Limit the dataset size to 20,000 samples\n",
        "total_size = min(len(dataset), 20000)  # Use the smaller of the dataset size or 20,000\n",
        "\n",
        "# Define proportions\n",
        "train_ratio = 0.8  # 80% training\n",
        "test_ratio = 0.2   # 20% testing\n",
        "\n",
        "# Compute split sizes\n",
        "train_size = int(train_ratio * total_size)\n",
        "test_size = total_size - train_size\n",
        "\n",
        "# Take a subset of the dataset if the dataset is larger than 20,000\n",
        "subset_indices = torch.randperm(len(dataset))[:total_size]  # Randomly select 20,000 indices\n",
        "subset_dataset = torch.utils.data.Subset(dataset, subset_indices)\n",
        "\n",
        "# Randomly split the subset dataset\n",
        "train_data, test_data = torch.utils.data.random_split(subset_dataset, [train_size, test_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "H0Li5cpuKDpa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LastTimeStep(nn.Module):\n",
        "    \"\"\"\n",
        "    A class for extracting the hidden activations of the last time step following\n",
        "    the output of a PyTorch RNN module.\n",
        "    \"\"\"\n",
        "    def __init__(self, rnn_layers=1, bidirectional=False):\n",
        "        super(LastTimeStep, self).__init__()\n",
        "        self.rnn_layers = rnn_layers\n",
        "        if bidirectional:\n",
        "            self.num_driections = 2\n",
        "        else:\n",
        "            self.num_driections = 1\n",
        "\n",
        "    def forward(self, input):\n",
        "        #Result is either a tupe (out, h_t)\n",
        "        #or a tuple (out, (h_t, c_t))\n",
        "        rnn_output = input[0]\n",
        "        last_step = input[1] #this will be h_t\n",
        "        if(type(last_step) == tuple):#unless it's a tuple,\n",
        "            last_step = last_step[0]#then h_t is the first item in the tuple\n",
        "\n",
        "        batch_size = last_step.shape[1] #per docs, shape is: '(num_layers * num_directions, batch, hidden_size)'\n",
        "        #reshaping so that everything is separate\n",
        "        last_step = last_step.view(self.rnn_layers, self.num_driections, batch_size, -1)\n",
        "        #We want the last layer's results\n",
        "        last_step = last_step[self.rnn_layers-1]\n",
        "        #Re order so batch comes first\n",
        "        last_step = last_step.permute(1, 0, 2)\n",
        "\n",
        "        #Finally, flatten the last two dimensions into one\n",
        "        return last_step.reshape(batch_size, -1)\n"
      ],
      "metadata": {
        "id": "Y6LCRKYOKY2M"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from tqdm.autonotebook import tqdm\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "def visualize2DSoftmax(X, y, model):\n",
        "    \"\"\"Function to visualize the classification boundary of a learned model on a 2-D dataset\n",
        "\n",
        "    Arguments:\n",
        "    X -- a numpy array of shape (2, N), where N is the number of data points.\n",
        "    y -- a numpy array of shape (N,), which contains values of either \"0\" or \"1\" for two different classes\n",
        "    model -- a PyTorch Module object that represents a classifer to visualize. s\n",
        "    \"\"\"\n",
        "    x_min = np.min(X[:,0])-0.5\n",
        "    x_max = np.max(X[:,0])+0.5\n",
        "    y_min = np.min(X[:,1])-0.5\n",
        "    y_max = np.max(X[:,1])+0.5\n",
        "    xv, yv = np.meshgrid(np.linspace(x_min, x_max, num=20), np.linspace(y_min, y_max, num=20), indexing='ij')\n",
        "    xy_v = np.hstack((xv.reshape(-1,1), yv.reshape(-1,1)))\n",
        "    with torch.no_grad():\n",
        "        preds = model(torch.tensor(xy_v, dtype=torch.float32))\n",
        "        preds = F.softmax(preds, dim=1).numpy()\n",
        "\n",
        "    cs = plt.contourf(xv, yv, preds[:,0].reshape(20,20), levels=np.linspace(0,1,num=20), cmap=plt.cm.RdYlBu)\n",
        "    sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, style=y, ax=cs.ax)\n",
        "\n",
        "def run_epoch(model, optimizer, data_loader, loss_func, device, results, score_funcs, prefix=\"\", desc=None):\n",
        "    \"\"\"\n",
        "    model -- the PyTorch model / \"Module\" to run for one epoch\n",
        "    optimizer -- the object that will update the weights of the network\n",
        "    data_loader -- DataLoader object that returns tuples of (input, label) pairs.\n",
        "    loss_func -- the loss function that takes in two arguments, the model outputs and the labels, and returns a score\n",
        "    device -- the compute lodation to perform training\n",
        "    score_funcs -- a dictionary of scoring functions to use to evalue the performance of the model\n",
        "    prefix -- a string to pre-fix to any scores placed into the _results_ dictionary.\n",
        "    desc -- a description to use for the progress bar.\n",
        "    \"\"\"\n",
        "    running_loss = []\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    start = time.time()\n",
        "    for inputs, labels in tqdm(data_loader, desc=desc, leave=False):\n",
        "        #Move the batch to the device we are using.\n",
        "        inputs = moveTo(inputs, device)\n",
        "        labels = moveTo(labels, device)\n",
        "\n",
        "        y_hat = model(inputs) #this just computed f_Θ(x(i))\n",
        "        # Compute loss.\n",
        "        loss = loss_func(y_hat, labels)\n",
        "\n",
        "        if model.training:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        #Now we are just grabbing some information we would like to have\n",
        "        running_loss.append(loss.item())\n",
        "\n",
        "        if len(score_funcs) > 0 and isinstance(labels, torch.Tensor):\n",
        "            #moving labels & predictions back to CPU for computing / storing predictions\n",
        "            labels = labels.detach().cpu().numpy()\n",
        "            y_hat = y_hat.detach().cpu().numpy()\n",
        "            #add to predictions so far\n",
        "            y_true.extend(labels.tolist())\n",
        "            y_pred.extend(y_hat.tolist())\n",
        "    #end training epoch\n",
        "    end = time.time()\n",
        "\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    if len(y_pred.shape) == 2 and y_pred.shape[1] > 1: #We have a classification problem, convert to labels\n",
        "        y_pred = np.argmax(y_pred, axis=1)\n",
        "    #Else, we assume we are working on a regression problem\n",
        "\n",
        "    results[prefix + \" loss\"].append( np.mean(running_loss) )\n",
        "    for name, score_func in score_funcs.items():\n",
        "        try:\n",
        "            results[prefix + \" \" + name].append( score_func(y_true, y_pred) )\n",
        "        except:\n",
        "            results[prefix + \" \" + name].append(float(\"NaN\"))\n",
        "    return end-start #time spent on epoch\n",
        "\n",
        "def train_network(model, loss_func, train_loader, test_loader=None, score_funcs=None,\n",
        "                         epochs=50, device=\"cpu\", checkpoint_file=None, lr=0.001):\n",
        "    \"\"\"Train simple neural networks\n",
        "\n",
        "    Keyword arguments:\n",
        "    model -- the PyTorch model / \"Module\" to train\n",
        "    loss_func -- the loss function that takes in batch in two arguments, the model outputs and the labels, and returns a score\n",
        "    train_loader -- PyTorch DataLoader object that returns tuples of (input, label) pairs.\n",
        "    test_loader -- Optional PyTorch DataLoader to evaluate on after every epoch\n",
        "    score_funcs -- A dictionary of scoring functions to use to evalue the performance of the model\n",
        "    epochs -- the number of training epochs to perform\n",
        "    device -- the compute lodation to perform training\n",
        "\n",
        "    \"\"\"\n",
        "    to_track = [\"epoch\", \"total time\", \"train loss\"]\n",
        "    if test_loader is not None:\n",
        "        to_track.append(\"test loss\")\n",
        "    for eval_score in score_funcs:\n",
        "        to_track.append(\"train \" + eval_score )\n",
        "        if test_loader is not None:\n",
        "            to_track.append(\"test \" + eval_score )\n",
        "\n",
        "    total_train_time = 0 #How long have we spent in the training loop?\n",
        "    results = {}\n",
        "    #Initialize every item with an empty list\n",
        "    for item in to_track:\n",
        "        results[item] = []\n",
        "\n",
        "    #SGD is Stochastic Gradient Decent.\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    #Place the model on the correct compute resource (CPU or GPU)\n",
        "    model.to(device)\n",
        "    for epoch in tqdm(range(epochs), desc=\"Epoch\"):\n",
        "        model = model.train()#Put our model in training mode\n",
        "\n",
        "        total_train_time += run_epoch(model, optimizer, train_loader, loss_func, device, results, score_funcs, prefix=\"train\", desc=\"Training\")\n",
        "\n",
        "        results[\"total time\"].append( total_train_time )\n",
        "        results[\"epoch\"].append( epoch )\n",
        "\n",
        "        if test_loader is not None:\n",
        "            model = model.eval()\n",
        "            with torch.no_grad():\n",
        "                run_epoch(model, optimizer, test_loader, loss_func, device, results, score_funcs, prefix=\"test\", desc=\"Testing\")\n",
        "\n",
        "    if checkpoint_file is not None:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'results' : results\n",
        "            }, checkpoint_file)\n",
        "\n",
        "    return pd.DataFrame.from_dict(results)\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "class View(nn.Module):\n",
        "    def __init__(self, *shape):\n",
        "        super(View, self).__init__()\n",
        "        self.shape = shape\n",
        "    def forward(self, input):\n",
        "        return input.view(*self.shape)\n",
        "\n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, lambd):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.lambd = lambd\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.lambd(x)\n",
        "\n",
        "class DebugShape(nn.Module):\n",
        "    \"\"\"\n",
        "    Module that is useful to help debug your neural network architecture.\n",
        "    Insert this module between layers and it will print out the shape of\n",
        "    that layer.\n",
        "    \"\"\"\n",
        "    def forward(self, input):\n",
        "        print(input.shape)\n",
        "        return input\n",
        "\n",
        "def weight_reset(m):\n",
        "    \"\"\"\n",
        "    Go through a PyTorch module m and reset all the weights to an initial random state\n",
        "    \"\"\"\n",
        "    if \"reset_parameters\" in dir(m):\n",
        "        m.reset_parameters()\n",
        "    return\n",
        "\n",
        "def moveTo(obj, device):\n",
        "    \"\"\"\n",
        "    obj: the python object to move to a device, or to move its contents to a device\n",
        "    device: the compute device to move objects to\n",
        "    \"\"\"\n",
        "    if hasattr(obj, \"to\"):\n",
        "        return obj.to(device)\n",
        "    elif isinstance(obj, list):\n",
        "        return [moveTo(x, device) for x in obj]\n",
        "    elif isinstance(obj, tuple):\n",
        "        return tuple(moveTo(list(obj), device))\n",
        "    elif isinstance(obj, set):\n",
        "        return set(moveTo(list(obj), device))\n",
        "    elif isinstance(obj, dict):\n",
        "        to_ret = dict()\n",
        "        for key, value in obj.items():\n",
        "            to_ret[moveTo(key, device)] = moveTo(value, device)\n",
        "        return to_ret\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "def train_network(model, loss_func, train_loader, val_loader=None, test_loader=None,score_funcs=None,\n",
        "                         epochs=50, device=\"cpu\", checkpoint_file=None,\n",
        "                         lr_schedule=None, optimizer=None, disable_tqdm=False\n",
        "                        ):\n",
        "    \"\"\"Train simple neural networks\n",
        "\n",
        "    Keyword arguments:\n",
        "    model -- the PyTorch model / \"Module\" to train\n",
        "    loss_func -- the loss function that takes in batch in two arguments, the model outputs and the labels, and returns a score\n",
        "    train_loader -- PyTorch DataLoader object that returns tuples of (input, label) pairs.\n",
        "    val_loader -- Optional PyTorch DataLoader to evaluate on after every epoch\n",
        "    test_loader -- Optional PyTorch DataLoader to evaluate on after every epoch\n",
        "    score_funcs -- A dictionary of scoring functions to use to evalue the performance of the model\n",
        "    epochs -- the number of training epochs to perform\n",
        "    device -- the compute lodation to perform training\n",
        "    lr_schedule -- the learning rate schedule used to alter \\eta as the model trains. If this is not None than the user must also provide the optimizer to use.\n",
        "    optimizer -- the method used to alter the gradients for learning.\n",
        "\n",
        "    \"\"\"\n",
        "    if score_funcs == None:\n",
        "        score_funcs = {}#Empty set\n",
        "\n",
        "    to_track = [\"epoch\", \"total time\", \"train loss\"]\n",
        "    if val_loader is not None:\n",
        "        to_track.append(\"val loss\")\n",
        "    if test_loader is not None:\n",
        "        to_track.append(\"test loss\")\n",
        "    for eval_score in score_funcs:\n",
        "        to_track.append(\"train \" + eval_score )\n",
        "        if val_loader is not None:\n",
        "            to_track.append(\"val \" + eval_score )\n",
        "        if test_loader is not None:\n",
        "            to_track.append(\"test \"+ eval_score )\n",
        "\n",
        "    total_train_time = 0 #How long have we spent in the training loop?\n",
        "    results = {}\n",
        "    #Initialize every item with an empty list\n",
        "    for item in to_track:\n",
        "        results[item] = []\n",
        "\n",
        "\n",
        "    if optimizer == None:\n",
        "        #The AdamW optimizer is a good default optimizer\n",
        "        optimizer = torch.optim.AdamW(model.parameters())\n",
        "        del_opt = True\n",
        "    else:\n",
        "        del_opt = False\n",
        "\n",
        "    #Place the model on the correct compute resource (CPU or GPU)\n",
        "    model.to(device)\n",
        "    for epoch in tqdm(range(epochs), desc=\"Epoch\", disable=disable_tqdm):\n",
        "        model = model.train()#Put our model in training mode\n",
        "\n",
        "        total_train_time += run_epoch(model, optimizer, train_loader, loss_func, device, results, score_funcs, prefix=\"train\", desc=\"Training\")\n",
        "\n",
        "        results[\"epoch\"].append( epoch )\n",
        "        results[\"total time\"].append( total_train_time )\n",
        "\n",
        "\n",
        "        if val_loader is not None:\n",
        "            model = model.eval() #Set the model to \"evaluation\" mode, b/c we don't want to make any updates!\n",
        "            with torch.no_grad():\n",
        "                run_epoch(model, optimizer, val_loader, loss_func, device, results, score_funcs, prefix=\"val\", desc=\"Validating\")\n",
        "\n",
        "        #In PyTorch, the convention is to update the learning rate after every epoch\n",
        "        if lr_schedule is not None:\n",
        "            if isinstance(lr_schedule, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                lr_schedule.step(results[\"val loss\"][-1])\n",
        "            else:\n",
        "                lr_schedule.step()\n",
        "\n",
        "        if test_loader is not None:\n",
        "            model = model.eval() #Set the model to \"evaluation\" mode, b/c we don't want to make any updates!\n",
        "            with torch.no_grad():\n",
        "                run_epoch(model, optimizer, test_loader, loss_func, device, results, score_funcs, prefix=\"test\", desc=\"Testing\")\n",
        "\n",
        "\n",
        "        if checkpoint_file is not None:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'results' : results\n",
        "                }, checkpoint_file)\n",
        "    if del_opt:\n",
        "        del optimizer\n",
        "\n",
        "    return pd.DataFrame.from_dict(results)\n",
        "\n",
        "### RNN utility Classes\n",
        "\n",
        "class LastTimeStep(nn.Module):\n",
        "    \"\"\"\n",
        "    A class for extracting the hidden activations of the last time step following\n",
        "    the output of a PyTorch RNN module.\n",
        "    \"\"\"\n",
        "    def __init__(self, rnn_layers=1, bidirectional=False):\n",
        "        super(LastTimeStep, self).__init__()\n",
        "        self.rnn_layers = rnn_layers\n",
        "        if bidirectional:\n",
        "            self.num_driections = 2\n",
        "        else:\n",
        "            self.num_driections = 1\n",
        "\n",
        "    def forward(self, input):\n",
        "        #Result is either a tupe (out, h_t)\n",
        "        #or a tuple (out, (h_t, c_t))\n",
        "        rnn_output = input[0]\n",
        "\n",
        "        last_step = input[1]\n",
        "        if(type(last_step) == tuple):\n",
        "            last_step = last_step[0]\n",
        "        batch_size = last_step.shape[1] #per docs, shape is: '(num_layers * num_directions, batch, hidden_size)'\n",
        "\n",
        "        last_step = last_step.view(self.rnn_layers, self.num_driections, batch_size, -1)\n",
        "        #We want the last layer's results\n",
        "        last_step = last_step[self.rnn_layers-1]\n",
        "        #Re order so batch comes first\n",
        "        last_step = last_step.permute(1, 0, 2)\n",
        "        #Finally, flatten the last two dimensions into one\n",
        "        return last_step.reshape(batch_size, -1)\n",
        "\n",
        "class EmbeddingPackable(nn.Module):\n",
        "    \"\"\"\n",
        "    The embedding layer in PyTorch does not support Packed Sequence objects.\n",
        "    This wrapper class will fix that. If a normal input comes in, it will\n",
        "    use the regular Embedding layer. Otherwise, it will work on the packed\n",
        "    sequence to return a new Packed sequence of the appropriate result.\n",
        "    \"\"\"\n",
        "    def __init__(self, embd_layer):\n",
        "        super(EmbeddingPackable, self).__init__()\n",
        "        self.embd_layer = embd_layer\n",
        "\n",
        "    def forward(self, input):\n",
        "        if type(input) == torch.nn.utils.rnn.PackedSequence:\n",
        "            # We need to unpack the input,\n",
        "            sequences, lengths = torch.nn.utils.rnn.pad_packed_sequence(input.cpu(), batch_first=True)\n",
        "            #Embed it\n",
        "            sequences = self.embd_layer(sequences.to(input.data.device))\n",
        "            #And pack it into a new sequence\n",
        "            return torch.nn.utils.rnn.pack_padded_sequence(sequences, lengths.cpu(),\n",
        "                                                           batch_first=True, enforce_sorted=False)\n",
        "        else:#apply to normal data\n",
        "            return self.embd_layer(input)\n",
        "\n",
        "\n",
        "\n",
        "### Attention Mechanism Layers\n",
        "\n",
        "class ApplyAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    This helper module is used to apply the results of an attention mechanism toa set of inputs.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ApplyAttention, self).__init__()\n",
        "\n",
        "    def forward(self, states, attention_scores, mask=None):\n",
        "        \"\"\"\n",
        "        states: (B, T, H) shape giving the T different possible inputs\n",
        "        attention_scores: (B, T, 1) score for each item at each context\n",
        "        mask: None if all items are present. Else a boolean tensor of shape\n",
        "            (B, T), with `True` indicating which items are present / valid.\n",
        "\n",
        "        returns: a tuple with two tensors. The first tensor is the final context\n",
        "        from applying the attention to the states (B, H) shape. The second tensor\n",
        "        is the weights for each state with shape (B, T, 1).\n",
        "        \"\"\"\n",
        "\n",
        "        if mask is not None:\n",
        "            #set everything not present to a large negative value that will cause vanishing gradients\n",
        "            attention_scores[~mask] = -1000.0\n",
        "        #compute the weight for each score\n",
        "        weights = F.softmax(attention_scores, dim=1) #(B, T, 1) still, but sum(T) = 1\n",
        "\n",
        "        final_context = (states*weights).sum(dim=1) #(B, T, D) * (B, T, 1) -> (B, D)\n",
        "        return final_context, weights\n",
        "\n",
        "class AttentionAvg(nn.Module):\n",
        "\n",
        "    def __init__(self, attnScore):\n",
        "        super(AttentionAvg, self).__init__()\n",
        "        self.score = attnScore\n",
        "\n",
        "    def forward(self, states, context, mask=None):\n",
        "        \"\"\"\n",
        "        states: (B, T, D) shape\n",
        "        context: (B, D) shape\n",
        "        output: (B, D), a weighted av\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        B = states.size(0)\n",
        "        T = states.size(1)\n",
        "        D = states.size(2)\n",
        "\n",
        "        scores = self.score(states, context) #(B, T, 1)\n",
        "\n",
        "        if mask is not None:\n",
        "            scores[~mask] = float(-10000)\n",
        "        weights = F.softmax(scores, dim=1) #(B, T, 1) still, but sum(T) = 1\n",
        "\n",
        "        context = (states*weights).sum(dim=1) #(B, T, D) * (B, T, 1) -> (B, D, 1)\n",
        "\n",
        "\n",
        "        return context.view(B, D) #Flatten this out to (B, D)\n",
        "\n",
        "\n",
        "class AdditiveAttentionScore(nn.Module):\n",
        "\n",
        "    def __init__(self, D):\n",
        "        super(AdditiveAttentionScore, self).__init__()\n",
        "        self.v = nn.Linear(D, 1)\n",
        "        self.w = nn.Linear(2*D, D)\n",
        "\n",
        "    def forward(self, states, context):\n",
        "        \"\"\"\n",
        "        states: (B, T, D) shape\n",
        "        context: (B, D) shape\n",
        "        output: (B, T, 1), giving a score to each of the T items based on the context D\n",
        "\n",
        "        \"\"\"\n",
        "        T = states.size(1)\n",
        "        #Repeating the values T times\n",
        "        context = torch.stack([context for _ in range(T)], dim=1) #(B, D) -> (B, T, D)\n",
        "        state_context_combined = torch.cat((states, context), dim=2) #(B, T, D) + (B, T, D)  -> (B, T, 2*D)\n",
        "        scores = self.v(torch.tanh(self.w(state_context_combined)))\n",
        "        return scores\n",
        "\n",
        "class GeneralScore(nn.Module):\n",
        "\n",
        "    def __init__(self, D):\n",
        "        super(GeneralScore, self).__init__()\n",
        "        self.w = nn.Bilinear(D, D, 1)\n",
        "\n",
        "    def forward(self, states, context):\n",
        "        \"\"\"\n",
        "        states: (B, T, D) shape\n",
        "        context: (B, D) shape\n",
        "        output: (B, T, 1), giving a score to each of the T items based on the context D\n",
        "\n",
        "        \"\"\"\n",
        "        T = states.size(1)\n",
        "        D = states.size(2)\n",
        "        #Repeating the values T times\n",
        "        context = torch.stack([context for _ in range(T)], dim=1) #(B, D) -> (B, T, D)\n",
        "        scores = self.w(states, context) #(B, T, D) -> (B, T, 1)\n",
        "        return scores\n",
        "\n",
        "class DotScore(nn.Module):\n",
        "\n",
        "    def __init__(self, D):\n",
        "        super(DotScore, self).__init__()\n",
        "\n",
        "    def forward(self, states, context):\n",
        "        \"\"\"\n",
        "        states: (B, T, D) shape\n",
        "        context: (B, D) shape\n",
        "        output: (B, T, 1), giving a score to each of the T items based on the context D\n",
        "\n",
        "        \"\"\"\n",
        "        T = states.size(1)\n",
        "        D = states.size(2)\n",
        "\n",
        "        scores = torch.bmm(states,context.unsqueeze(2)) / np.sqrt(D) #(B, T, D) -> (B, T, 1)\n",
        "        return scores\n",
        "\n",
        "def getMaskByFill(x, time_dimension=1, fill=0):\n",
        "    \"\"\"\n",
        "    x: the original input with three or more dimensions, (B, ..., T, ...)\n",
        "        which may have unsued items in the tensor. B is the batch size,\n",
        "        and T is the time dimension.\n",
        "    time_dimension: the axis in the tensor `x` that denotes the time dimension\n",
        "    fill: the constant used to denote that an item in the tensor is not in use,\n",
        "        and should be masked out (`False` in the mask).\n",
        "\n",
        "    return: A boolean tensor of shape (B, T), where `True` indicates the value\n",
        "        at that time is good to use, and `False` that it is not.\n",
        "    \"\"\"\n",
        "    to_sum_over = list(range(1,len(x.shape))) #skip the first dimension 0 because that is the batch dimension\n",
        "\n",
        "    if time_dimension in to_sum_over:\n",
        "        to_sum_over.remove(time_dimension)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #Special case is when shape is (B, D), then it is an embedding layer. We just return the values that are good\n",
        "        if len(to_sum_over) == 0:\n",
        "            return (x != fill)\n",
        "        #(x!=fill) determines locations that might be unused, beause they are\n",
        "        #missing the fill value we are looking for to indicate lack of use.\n",
        "        #We then count the number of non-fill values over everything in that\n",
        "        #time slot (reducing changes the shape to (B, T)). If any one entry\n",
        "        #is non equal to this value, the item represent must be in use -\n",
        "        #so return a value of true.\n",
        "        mask = torch.sum((x != fill), dim=to_sum_over) > 0\n",
        "    return mask\n",
        "\n",
        "class LanguageNameDataset(Dataset):\n",
        "\n",
        "    def __init__(self, lang_name_dict, vocabulary):\n",
        "        self.label_names = [x for x in lang_name_dict.keys()]\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        self.vocabulary = vocabulary\n",
        "        for y, language in enumerate(self.label_names):\n",
        "            for sample in lang_name_dict[language]:\n",
        "                self.data.append(sample)\n",
        "                self.labels.append(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def string2InputVec(self, input_string):\n",
        "        \"\"\"\n",
        "        This method will convert any input string into a vector of long values, according to the vocabulary used by this object.\n",
        "        input_string: the string to convert to a tensor\n",
        "        \"\"\"\n",
        "        T = len(input_string) #How many characters long is the string?\n",
        "\n",
        "        #Create a new tensor to store the result in\n",
        "        name_vec = torch.zeros((T), dtype=torch.long)\n",
        "        #iterate through the string and place the appropriate values into the tensor\n",
        "        for pos, character in enumerate(input_string):\n",
        "            name_vec[pos] = self.vocabulary[character]\n",
        "\n",
        "        return name_vec\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.data[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        #Conver the correct class label into a tensor for PyTorch\n",
        "        label_vec = torch.tensor([label], dtype=torch.long)\n",
        "\n",
        "        return self.string2InputVec(name), label\n",
        "\n",
        "def pad_and_pack(batch):\n",
        "    #1, 2, & 3: organize the batch input lengths, inputs, and outputs as seperate lists\n",
        "    input_tensors = []\n",
        "    labels = []\n",
        "    lengths = []\n",
        "    for x, y in batch:\n",
        "        input_tensors.append(x)\n",
        "        labels.append(y)\n",
        "        lengths.append(x.shape[0]) #Assume shape is (T, *)\n",
        "    #4: create the padded version of the input\n",
        "    x_padded = torch.nn.utils.rnn.pad_sequence(input_tensors, batch_first=False)\n",
        "    #5: create the packed version from the padded & lengths\n",
        "    x_packed = torch.nn.utils.rnn.pack_padded_sequence(x_padded, lengths, batch_first=False, enforce_sorted=False)\n",
        "    #Convert the lengths into a tensor\n",
        "    y_batched = torch.as_tensor(labels, dtype=torch.long)\n",
        "    #6: return a tuple of the packed inputs and their labels\n",
        "    return x_packed, y_batched"
      ],
      "metadata": {
        "id": "XCb2SINWBil7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    input_sequence = torch.tensor([0, 1, 1, 0, 2], dtype=torch.long)\n",
        "    embd = nn.Embedding(3, 2)\n",
        "    x_seq = embd(input_sequence)\n",
        "\n",
        "    print(input_sequence.shape, x_seq.shape)\n",
        "    print(x_seq)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62EJNiFUHOfs",
        "outputId": "06273efc-9c3b-494d-d448-f9413dd91a31"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5]) torch.Size([5, 2])\n",
            "tensor([[-1.2949, -2.5662],\n",
            "        [-0.0086,  1.5356],\n",
            "        [-0.0086,  1.5356],\n",
            "        [-1.2949, -2.5662],\n",
            "        [ 2.0602, -0.7500]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = 64\n",
        "vocab_size = len(all_letters)\n",
        "hidden_nodes = 256\n",
        "classes = len(dataset.label_names)\n",
        "\n",
        "first_rnn = nn.Sequential(\n",
        "  nn.Embedding(vocab_size, D), #(B, T) -> (B, T, D)\n",
        "  nn.RNN(D, hidden_nodes, batch_first=True), #(B, T, D) -> ( (B,T,D) , (S, B, D)  )\n",
        "  #the tanh activation is built into the RNN object, so we don't need to do it here\n",
        "  LastTimeStep(), #We need to take the RNN output and reduce it to one item, (B, D)\n",
        "  nn.Linear(hidden_nodes, classes), #(B, D) -> (B, classes)\n",
        ")\n"
      ],
      "metadata": {
        "id": "Su-cA60AHmDI"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset = LanguageNameDataset(emotion_data, alphabet)\n",
        "classes = len(dataset.label_names)\n",
        "device = 'cpu'\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "\n",
        "B = 30\n",
        "train_loader = DataLoader(train_data, batch_size=B, shuffle=True, \\\n",
        "                          collate_fn=pad_and_pack)\n",
        "test_loader = DataLoader(test_data, batch_size=B, shuffle=False, \\\n",
        "                         collate_fn=pad_and_pack)\n",
        "\n",
        "rnn_packed = nn.Sequential(\n",
        "  EmbeddingPackable(nn.Embedding(vocab_size, D)), #(B, T) -> (B, T, D)\n",
        "  nn.RNN(D, hidden_nodes, batch_first=True), #(B, T, D) -> ( (B,T,D) , (S, B, D)  )\n",
        "  LastTimeStep(), #We need to take the RNN output and reduce it to one item, (B, D)\n",
        "  nn.Linear(hidden_nodes, classes), #(B, D) -> (B, classes)\n",
        ")\n",
        "\n",
        "rnn_packed.to(device)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LaM2z2OKe20",
        "outputId": "d1ceb1f2-15b7-4362-fcb1-553be535adcf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): EmbeddingPackable(\n",
              "    (embd_layer): Embedding(57, 64)\n",
              "  )\n",
              "  (1): RNN(64, 256, batch_first=True)\n",
              "  (2): LastTimeStep()\n",
              "  (3): Linear(in_features=256, out_features=28, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_3layer = nn.Sequential(\n",
        "  EmbeddingPackable(nn.Embedding(vocab_size, D)), #(B, T) -> (B, T, D)\n",
        "  nn.RNN(D, hidden_nodes, num_layers=3, batch_first=True), #(B, T, D) -> ( (B,T,D) , (S, B, D)  )\n",
        "  LastTimeStep(rnn_layers=3), #We need to take the RNN output and reduce it to one item, (B, D)\n",
        "  nn.Linear(hidden_nodes, classes), #(B, D) -> (B, classes)\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam(rnn_3layer.parameters(), lr=0.001)  # Lower lr for stability\n",
        "rnn_3layer.to(device)\n",
        "\n",
        "rnn_3layer_results = train_network(\n",
        "    rnn_3layer,\n",
        "    loss_func,\n",
        "    train_loader,\n",
        "    test_loader=test_loader,\n",
        "    score_funcs={'Accuracy': accuracy_score},\n",
        "    device=device,\n",
        "    epochs=10,\n",
        "    optimizer=optimizer\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c35a5b01828a4cdc962f1f749b451ded",
            "ec535feda363412b976c7ce939a53b3c",
            "18f510767b8942b784cb1b657ca5020d",
            "5044ba0db28b4c58ac48cc3cd7bc58d1",
            "6bb2d4eade0541b1b7e0ff5509f3e278",
            "7bc1d86f0cb6486c8d426436a1e0643a",
            "5d7dae83338641b7971d0f34f7a53eb2",
            "1087c2f33c3a4010b3eaf6d476f6ffdd",
            "cbac255c43024943831d8255297d1671",
            "0291a05c3a174b3598f91795c82565b9",
            "71862daff860477d8e0ad8077e81fea4",
            "d51054dee4ed4d328aac1861ebee8ac2",
            "f199663bddec4981a32cf48e83bd240a",
            "d0063e5676f341a2ba03290f3d3cc965",
            "e3b292a91c154628a9c4ffe4818f1858",
            "f5b1870605f940adaeaaedcc0dc53b1b",
            "5161cf9e50904688997f78c41eeeed3d",
            "282afba645e640bf9ae57ef45aecb27b",
            "e854655767c845c6b12c1b6cd5c6fd30",
            "047aad51e53143e191b6b6b2a7798ad9",
            "1e50c09f0ab94f96a7e79dbaf74a52de",
            "501520f60bd7451e83ba32125c8b2932"
          ]
        },
        "id": "QenzcbcyVrRm",
        "outputId": "60967687-9e7b-4a7f-f920-cba3b5629b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c35a5b01828a4cdc962f1f749b451ded"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/534 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d51054dee4ed4d328aac1861ebee8ac2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.lineplot(x='epoch', y='test Accuracy', data=rnn_3layer_results,\n",
        "label='RNN: 3-Layer')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "Pa9QVHXgUkqJ",
        "outputId": "8e31d8a9-0a6a-4ca4-99e1-2ae15b4a1942"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: xlabel='epoch', ylabel='test Accuracy'>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}